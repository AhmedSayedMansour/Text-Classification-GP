{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle\n",
    "import TextNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNLP(data):\n",
    "    nlpText = TextNLP.TextNLP()\n",
    "    for i , _ in enumerate(data):\n",
    "        data[i] = nlpText.prepareData(data[i])\n",
    "        data[i] = nlpText.slang(data[i])\n",
    "        data[i] = nlpText.removeStopWords(data[i])\n",
    "        data[i] = nlpText.stemmAndLemmatization(data[i])\n",
    "        data[i] = nlpText.removepunctuations(data[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading the data set - training data.\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, remove=('headers','footers', 'quotes'))\n",
    "twenty_test  = fetch_20newsgroups(subset='test', shuffle=True, remove=('headers','footers', 'quotes'))\n",
    "# ======================= NLP ========================== \n",
    "train = runNLP(twenty_train.data)\n",
    "test = runNLP(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class techniques:\n",
    "\n",
    "    def naiveBayes(self,data, target):\n",
    "        stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "        model = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "        model = model.fit(data, target)\n",
    "        return model\n",
    "\n",
    "    def SVM(self, data, target):\n",
    "        model = Pipeline([('vect',CountVectorizer()), ('tfidf', TfidfTransformer()),('clf-svm', SGDClassifier(loss='hinge',                penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
    "        model = model.fit(data, target)\n",
    "        return model\n",
    "    \n",
    "    def LinearSVC(self, data, target):\n",
    "        model = Pipeline([('vect',CountVectorizer()), ('tfidf', TfidfTransformer()),('linear-svm', LinearSVC())])\n",
    "        model = model.fit(data, target)\n",
    "        return model\n",
    "\n",
    "    def RandomForest(self, data, target):\n",
    "        model = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf-RF', RandomForestClassifier                       (n_estimators=100, random_state=0, max_depth=20))])\n",
    "        model.fit(data, target)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= Training =======================\n",
    "technique = techniques()\n",
    "#naiveBayes\n",
    "naiveBayesModel = technique.naiveBayes(train, twenty_train.target)\n",
    "#SVM\n",
    "SVMModel = technique.SVM(train, twenty_train.target)\n",
    "#RandomForest\n",
    "RandomForestModel = technique.RandomForest(train, twenty_train.target)\n",
    "#LinearSVC\n",
    "LienarSVCModel = technique.LinearSVC(train, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.694105151354222\n"
    }
   ],
   "source": [
    "# ======================= Testing =======================\n",
    "predicted = LienarSVCModel.predict(test)\n",
    "m = np.mean(predicted == twenty_test.target)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the models\n",
    "\n",
    "#naiveBayesModel\n",
    "with open('savedModels/naiveBayesModel', 'wb') as picklefile:\n",
    "    pickle.dump(naiveBayesModel,picklefile)\n",
    "\n",
    "#SVMModel\n",
    "with open('savedModels/SVMModel', 'wb') as picklefile:\n",
    "    pickle.dump(SVMModel,picklefile)\n",
    "\n",
    "#naiveBayesModel\n",
    "with open('savedModels/RandomForestModel', 'wb') as picklefile:\n",
    "    pickle.dump(RandomForestModel,picklefile)\n",
    "\n",
    "#naiveBayesModel\n",
    "with open('savedModels/LienarSVCModel', 'wb') as picklefile:\n",
    "    pickle.dump(LienarSVCModel,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.694105151354222\n"
    }
   ],
   "source": [
    "#Loading the model\n",
    "with open('savedModels/LienarSVCModel', 'rb') as training_model:\n",
    "    loadedModel = pickle.load(training_model)\n",
    "#predict the loadedModel\n",
    "predicted = loadedModel.predict(test)\n",
    "m = np.mean(predicted == twenty_test.target)\n",
    "print (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1611934109617",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dd611110a353d997d32ab9a3a577087e569cb682f4339466cf5a17f22bab8f94"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}